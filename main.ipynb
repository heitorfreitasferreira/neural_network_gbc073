{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Callable, Union, Iterable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Constants\n",
    "num_experiments = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntandos os dados em um único DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_gathered(cities: list[str] = ['cleveland'], save: bool = False) -> pd.DataFrame:\n",
    "    columns = [\n",
    "        'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "        'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'\n",
    "    ]\n",
    "\n",
    "    def load_data(file_path: str) -> pd.DataFrame:\n",
    "        df = pd.read_csv(file_path, header=None, names=columns, na_values='?')\n",
    "        return df\n",
    "\n",
    "    files: list[str] = [f'./data/processed.{city}.data' for city in cities]\n",
    "\n",
    "    result_df = pd.concat([load_data(file)\n",
    "                          for file in files], ignore_index=True)\n",
    "    if save:\n",
    "\n",
    "        output_path = f'./data/heart_disease_{\"_\".join(cities)}.csv'\n",
    "        result_df.to_csv(output_path, index=False)\n",
    "        print(f\"Arquivo CSV criado com sucesso em: {output_path}\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré processamento dos dados\n",
    "\n",
    "Foram implementadas 2 alternativas para teste, uma em que os valores nulos são preenchidos, e outra em que os valores nulos são removidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_with_nil(original_df: pd.DataFrame, drop_nulls: bool = True) -> pd.DataFrame:\n",
    "    if drop_nulls:\n",
    "        return original_df.dropna()\n",
    "\n",
    "    df = original_df.copy()\n",
    "    # Substitua lacunas para frente do valor válido anterior em: 'trestbps'\n",
    "    df = df.fillna({'trestbps': df['trestbps'].ffill()})\n",
    "    # Substitua os valores ausentes pela média de cada coluna em: 'chol'\n",
    "    df = df.fillna({'chol': df['chol'].mean()})\n",
    "    # Substitua as lacunas do próximo valor válido em: 'fbs'\n",
    "    df = df.fillna({'fbs': df['fbs'].bfill()})\n",
    "    # Substitua os valores ausentes pela média de cada coluna em: 'thalach'\n",
    "    df = df.fillna({'thalach': df['thalach'].mean()})\n",
    "    # Substitua os valores ausentes pelo modo de cada coluna em: 'restecg'\n",
    "    df = df.fillna({'restecg': df['restecg'].mode()[0]})\n",
    "    # Substitua os valores ausentes pelo modo de cada coluna em: 'exang'\n",
    "    df = df.fillna({'exang': df['exang'].mode()[0]})\n",
    "    # Remover coluna: 'ca' (muitos nulls)\n",
    "    df = df.drop(columns=['ca'])\n",
    "    # Substitua lacunas para frente do valor válido anterior em: 'slope'\n",
    "    df = df.fillna({'slope': df['slope'].ffill()})\n",
    "    # Substitua os valores ausentes pelo modo de cada coluna em: 'thal'\n",
    "    df = df.fillna({'thal': df['thal'].mode()[0]})\n",
    "    # Substitua lacunas para frente do valor válido anterior em: 'oldpeak'\n",
    "    df = df.fillna({'oldpeak': df['oldpeak'].ffill()})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a normalização foi usado o MinMaxScaler, que transforma os dados para que fiquem entre 0 e 1. Transformando a coluna objetivo em 0 e 1. Onde 0 é saudável e 1 é doente, no banco de dados original os valores são [0..4], onde qualquer número >0 é não saudável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(original_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_clean = original_df.copy()\n",
    "    print(\"Quantidade de classes nos dados limpos:\")\n",
    "    print(df_clean['num'].value_counts())\n",
    "\n",
    "    df_clean['num'] = df_clean['num'].apply(\n",
    "        lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    df_clean_normalized = df_clean.copy()\n",
    "    df_clean_normalized = pd.DataFrame(scaler.fit_transform(\n",
    "        df_clean_normalized), columns=df_clean_normalized.columns)\n",
    "\n",
    "    df_clean_normalized.describe()\n",
    "\n",
    "    df_clean_normalized['num'] = df_clean_normalized['num'].astype(bool)\n",
    "\n",
    "    print(\"Quantidade de classes nos dados normalizados:\")\n",
    "    print(df_clean_normalized['num'].value_counts())\n",
    "\n",
    "    return df_clean_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = normalize(deal_with_nil(get_data_gathered()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicando a arquitetura do artigo\n",
    "\n",
    "| Parâmetro                | Valor       |\n",
    "|--------------------------|-------------|\n",
    "| Neurônios na camada de entrada | 12          |\n",
    "| Neurônios na camada de saída   | 2           |\n",
    "| Camadas ocultas               | 1            |\n",
    "| Neurônios na camada oculta    | 6            |\n",
    "| Épocas                        | 2000         |\n",
    "| Taxa de aprendizado           | 0.32         |\n",
    "| Momento                       | 0.72         |\n",
    "| Performance                   | 0.199        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('num', axis=1)\n",
    "y = df['num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo em treino e teste 60:40\n",
    "Foi feito assim como no artigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide o dataset em 60% treino e 40% teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Exibe os tamanhos dos conjuntos de treino e teste\n",
    "print(f'Tamanho do conjunto de treino: {X_train.shape[0]}')\n",
    "print(f'Tamanho do conjunto de teste: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model_60_40 = MLPClassifier(hidden_layer_sizes=(\n",
    "    6,), max_iter=2000, learning_rate_init=0.32, momentum=0.72, activation='logistic')\n",
    "\n",
    "model_60_40.fit(X_train, y_train)\n",
    "score = model_60_40.score(X_test, y_test)\n",
    "\n",
    "y_pred = model_60_40.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusão:')\n",
    "print(conf_matrix)\n",
    "\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print('Relatório de Classificação:')\n",
    "print(cr)\n",
    "\n",
    "\n",
    "def plot_classification_report_with_support(report):\n",
    "    # Exclude 'accuracy', 'macro avg', 'weighted avg'\n",
    "    labels = list(report.keys())[:-3]\n",
    "    metrics = ['precision', 'recall', 'f1-score', 'support']\n",
    "    data = np.array([[report[label][metric]\n",
    "                    for metric in metrics] for label in labels])\n",
    "    _, ax = plt.subplots(figsize=(12, 6))\n",
    "    cax = ax.matshow(data, cmap='coolwarm')\n",
    "    plt.xticks(range(len(metrics)), metrics)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    plt.colorbar(cax)\n",
    "    for (i, j), val in np.ndenumerate(data):\n",
    "        ax.text(j, i, f'{val:.2f}', ha='center', va='center', color='white')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Classes')\n",
    "    plt.title('Classification Report with Support')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plotting the classification report with support\n",
    "plot_classification_report_with_support(\n",
    "    classification_report(y_test, y_pred, output_dict=True)\n",
    ")\n",
    "print(f'F1-Score: {f1_score(y_test, y_pred)}')\n",
    "print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotando a matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos realizados\n",
    "\n",
    "Para padronizar os experimentos foi criado um framework que recebe quais parâmetros devem ser testados e retorna a média e desvio padrão dos resultados obtidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentType = Callable[[Union[str, int]], np.float64]\n",
    "ExperimentResults = Dict[Union[str, int], Dict[str, np.float64]]\n",
    "\n",
    "\n",
    "def experiment_runner(param_range: Iterable, experiment: ExperimentType, set_seed: bool = True) -> ExperimentResults:\n",
    "    \"\"\"\n",
    "        Run experiments with different parameters and return the best parameter, best score, and standard deviation.\n",
    "        Args:\n",
    "            param_range (Iterable): A range of parameters to be tested.\n",
    "            experiment (ExperimentType): A function that takes a parameter and returns a score.\n",
    "        Returns:\n",
    "            (Tuple[Tuple[Union[str, int], np.float64], np.float64]): A tuple containing the best parameter, best score, and standard deviation.\n",
    "    \"\"\"\n",
    "    over_all_results: ExperimentResults = {param: {} for param in param_range}\n",
    "    for param in param_range:\n",
    "        param_results = []\n",
    "        for seed in range(num_experiments):\n",
    "            if set_seed:\n",
    "                np.random.seed(seed)\n",
    "    \n",
    "            score = experiment(param)\n",
    "            param_results.append(score)\n",
    "        over_all_results[param]['mean'] = np.mean(param_results)\n",
    "        over_all_results[param]['std_dev'] = np.std(param_results)\n",
    "        over_all_results[param]['max'] = np.max(param_results)\n",
    "        over_all_results[param]['min'] = np.min(param_results)\n",
    "    return over_all_results\n",
    "\n",
    "\n",
    "def plot_experiment_results(results: ExperimentResults, x_label: str, y_label: str, title: str):\n",
    "    \"\"\"\n",
    "        Plot the results of an experiment.\n",
    "        Args:\n",
    "            results (ExperimentResults): The results of the experiment.\n",
    "            x_label (str): The label for the x-axis.\n",
    "            y_label (str): The label for the y-axis.\n",
    "            title (str): The title of the plot.\n",
    "    \"\"\"\n",
    "    x = list(results.keys())\n",
    "    y_mean = [results[param]['mean'] for param in x]\n",
    "    y_std_dev = [results[param]['std_dev'] for param in x]\n",
    "    y_max = [results[param]['max'] for param in x]\n",
    "    y_min = [results[param]['min'] for param in x]\n",
    "\n",
    "    plt.errorbar(x, y_mean, yerr=y_std_dev, fmt='o-',\n",
    "                 capsize=5, label='Mean ± Std Dev')\n",
    "    plt.plot(x, y_max, 'g--', label='Max')\n",
    "    plt.plot(x, y_min, 'r--', label='Min')\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira modificação: K Fold\n",
    "\n",
    "Nesta modificação iremos usar **kfold** com [2..20] splits ao invés de dividir em 60:40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_experiment(n_folds: Union[int, str]) -> np.float64:\n",
    "    assert isinstance(n_folds, int)\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "    model_kfold = MLPClassifier(hidden_layer_sizes=(\n",
    "        6,), max_iter=2000, learning_rate_init=0.32, momentum=0.72, activation='logistic')\n",
    "\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model_kfold.fit(X_train, y_train)\n",
    "        score = model_kfold.score(X_test, y_test)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "plot_experiment_results(\n",
    "    experiment_runner(range(2, 21), k_fold_experiment),\n",
    "    'Number of Folds',\n",
    "    'Score',\n",
    "    'K-Fold Cross Validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda modificação: Épocas\n",
    "\n",
    "Aqui variamos o número de épocas da arquitetura original.\n",
    "\n",
    "O valor incial utilizado foi 400, pois ao utilizar 200 a biblioca exibia avisos que não estava convergindo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_experiment(epochs: Union[int, str]) -> np.float64:\n",
    "    assert isinstance(epochs, int)\n",
    "    model_60_40 = MLPClassifier(hidden_layer_sizes=(\n",
    "        6,), max_iter=epochs, learning_rate_init=0.32, momentum=0.72, activation='logistic')\n",
    "\n",
    "    model_60_40.fit(X_train, y_train)\n",
    "    return np.float64(model_60_40.score(X_test, y_test))\n",
    "\n",
    "plot_experiment_results(\n",
    "    experiment_runner(range(400, 3001, 200), epoch_experiment, set_seed=False),\n",
    "    'Number of Epochs',\n",
    "    'Score',\n",
    "    'Epochs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando seeds\n",
    "\n",
    "Utilizando seeds, notamos que o número de épocas não afeta o resultado do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment_results(\n",
    "    experiment_runner(range(400, 3001, 200), epoch_experiment, set_seed=True),\n",
    "    'Number of Epochs',\n",
    "    'Score',\n",
    "    'Epochs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terceira Modificação: Função de Ativação\n",
    "\n",
    "Aqui testamos a arquitetura original com todas as funções de ativação disponíveis no sklearn (relu, identity, tanh, logistic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function_experiment(activation: Union[str, int]) -> np.float64:\n",
    "    assert isinstance(activation, str)\n",
    "    assert activation in ['relu', 'identity', 'tanh', 'logistic']\n",
    "    model_60_40 = MLPClassifier(hidden_layer_sizes=(\n",
    "        6,), max_iter=2000, learning_rate_init=0.32, momentum=0.72, activation=activation)  # type: ignore\n",
    "\n",
    "    model_60_40.fit(X_train, y_train)\n",
    "    return np.float64(model_60_40.score(X_test, y_test))\n",
    "\n",
    "\n",
    "plot_experiment_results(\n",
    "    experiment_runner(['relu', 'identity', 'tanh', 'logistic'],\n",
    "                      activation_function_experiment),\n",
    "    'Activation Function',\n",
    "    'Score',\n",
    "    'Activation Function'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarta Moficação: Número de Neurônios\n",
    "\n",
    "No artigo foram usados 6 neurônios na camada oculta, aqui testamos com 2, 4, 6, 8, 10, 12, 14, 16, 18, 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_neurons_experiment(number_of_neurons: Union[str, int]) -> np.float64:\n",
    "    assert isinstance(number_of_neurons, int)\n",
    "    model_60_40 = MLPClassifier(hidden_layer_sizes=(\n",
    "        number_of_neurons,), max_iter=2000, learning_rate_init=0.32, momentum=0.72, activation='logistic')\n",
    "\n",
    "    model_60_40.fit(X_train, y_train)\n",
    "    return np.float64(model_60_40.score(X_test, y_test))\n",
    "\n",
    "\n",
    "plot_experiment_results(\n",
    "    experiment_runner(range(2, 21), num_neurons_experiment),\n",
    "    'Number of Neurons',\n",
    "    'Score',\n",
    "    'Number of Neurons in Hidden Layer'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
